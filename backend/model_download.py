"""
AI å•†å“è§†è§’è½¬æ¢ Web åº”ç”¨ - æ¨¡å‹ä¸‹è½½è„šæœ¬

ä» HuggingFace ä¸‹è½½ Qwen-Image-Edit-2511 æ¨¡å‹å’Œç›¸å…³ LoRA æƒé‡ã€‚
ä½¿ç”¨ huggingface_hub åº“è¿›è¡Œä¸‹è½½ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ å’Œç¼“å­˜ã€‚

Requirements:
- 5.5: ä» HuggingFace åŠ è½½æ¨¡å‹
- 5.6: æ”¯æŒ qwen_image_vae, qwen_2.5_vl_7b, Qwen-Image-Edit-2511
- 5.7: æ”¯æŒ Lightning LoRA æƒé‡
"""

import os
from pathlib import Path
from typing import Dict, List, Optional
from dataclasses import dataclass


@dataclass
class ModelInfo:
    """æ¨¡å‹ä¿¡æ¯"""
    name: str                    # æœ¬åœ°æ–‡ä»¶å
    repo_id: str                 # HuggingFace ä»“åº“ ID
    filename: str                # HuggingFace æ–‡ä»¶è·¯å¾„
    subfolder: Optional[str]     # HuggingFace å­æ–‡ä»¶å¤¹
    local_dir: str               # æœ¬åœ°ç›®å½•ç±»å‹ (vae, clip, unet, loras)


# ============================================================================
# æ¨¡å‹é…ç½®
# ============================================================================

# æ¨¡å‹ä¸‹è½½é…ç½®
# åŸºäº Colab notebook ä¸­çš„ä¸‹è½½é“¾æ¥
MODELS: List[ModelInfo] = [
    # VAE - qwen_image_vae.safetensors
    # https://huggingface.co/Comfy-Org/Qwen-Image_ComfyUI/resolve/main/split_files/vae/qwen_image_vae.safetensors
    ModelInfo(
        name="qwen_image_vae.safetensors",
        repo_id="Comfy-Org/Qwen-Image_ComfyUI",
        filename="qwen_image_vae.safetensors",
        subfolder="split_files/vae",
        local_dir="vae",
    ),
    
    # CLIP - qwen_2.5_vl_7b.safetensors (fp8 scaled version)
    # https://huggingface.co/Comfy-Org/HunyuanVideo_1.5_repackaged/resolve/main/split_files/text_encoders/qwen_2.5_vl_7b_fp8_scaled.safetensors
    ModelInfo(
        name="qwen_2.5_vl_7b.safetensors",
        repo_id="Comfy-Org/HunyuanVideo_1.5_repackaged",
        filename="qwen_2.5_vl_7b_fp8_scaled.safetensors",
        subfolder="split_files/text_encoders",
        local_dir="clip",
    ),
    
    # UNET - Qwen-Image-Edit-2511.safetensors (bf16 version)
    # https://huggingface.co/Comfy-Org/Qwen-Image-Edit_ComfyUI/resolve/main/split_files/diffusion_models/qwen_image_edit_2511_bf16.safetensors
    ModelInfo(
        name="Qwen-Image-Edit-2511.safetensors",
        repo_id="Comfy-Org/Qwen-Image-Edit_ComfyUI",
        filename="qwen_image_edit_2511_bf16.safetensors",
        subfolder="split_files/diffusion_models",
        local_dir="unet",
    ),
    
    # LoRA - Lightning 4-steps
    # https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-4steps-V1.0.safetensors
    ModelInfo(
        name="Qwen-Image-Lightning-4steps-V1.0.safetensors",
        repo_id="lightx2v/Qwen-Image-Lightning",
        filename="Qwen-Image-Lightning-4steps-V1.0.safetensors",
        subfolder=None,
        local_dir="loras",
    ),
    
    # LoRA - Lightning 8-steps
    # https://huggingface.co/lightx2v/Qwen-Image-Lightning/resolve/main/Qwen-Image-Lightning-8steps-V1.0.safetensors
    ModelInfo(
        name="Qwen-Image-Lightning-8steps-V1.0.safetensors",
        repo_id="lightx2v/Qwen-Image-Lightning",
        filename="Qwen-Image-Lightning-8steps-V1.0.safetensors",
        subfolder=None,
        local_dir="loras",
    ),
]


def get_model_url(model: ModelInfo) -> str:
    """
    è·å–æ¨¡å‹çš„ HuggingFace ä¸‹è½½ URL
    
    Args:
        model: æ¨¡å‹ä¿¡æ¯
        
    Returns:
        å®Œæ•´çš„ä¸‹è½½ URL
    """
    base_url = f"https://huggingface.co/{model.repo_id}/resolve/main"
    if model.subfolder:
        return f"{base_url}/{model.subfolder}/{model.filename}"
    return f"{base_url}/{model.filename}"


def download_model_with_hf_hub(
    model: ModelInfo,
    cache_dir: Path,
    force_download: bool = False,
) -> Path:
    """
    ä½¿ç”¨ huggingface_hub ä¸‹è½½æ¨¡å‹
    
    Args:
        model: æ¨¡å‹ä¿¡æ¯
        cache_dir: ç¼“å­˜ç›®å½•
        force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
        
    Returns:
        ä¸‹è½½åçš„æ–‡ä»¶è·¯å¾„
    """
    from huggingface_hub import hf_hub_download
    
    # ç›®æ ‡ç›®å½•
    target_dir = cache_dir / model.local_dir
    target_dir.mkdir(parents=True, exist_ok=True)
    target_path = target_dir / model.name
    
    # å¦‚æœæ–‡ä»¶å·²å­˜åœ¨ä¸”ä¸å¼ºåˆ¶ä¸‹è½½ï¼Œç›´æ¥è¿”å›
    if target_path.exists() and not force_download:
        print(f"âœ… {model.name} å·²å­˜åœ¨äºç¼“å­˜")
        return target_path
    
    print(f"ğŸ“¥ ä¸‹è½½ {model.name}...")
    print(f"   ä»“åº“: {model.repo_id}")
    print(f"   æ–‡ä»¶: {model.subfolder}/{model.filename}" if model.subfolder else f"   æ–‡ä»¶: {model.filename}")
    
    try:
        # ä½¿ç”¨ hf_hub_download ä¸‹è½½
        downloaded_path = hf_hub_download(
            repo_id=model.repo_id,
            filename=f"{model.subfolder}/{model.filename}" if model.subfolder else model.filename,
            local_dir=str(target_dir),
            local_dir_use_symlinks=False,
            force_download=force_download,
        )
        
        # å¦‚æœä¸‹è½½çš„æ–‡ä»¶åä¸ç›®æ ‡æ–‡ä»¶åä¸åŒï¼Œé‡å‘½å
        downloaded_path = Path(downloaded_path)
        if downloaded_path.name != model.name:
            # ç§»åŠ¨æ–‡ä»¶åˆ°ç›®æ ‡ä½ç½®
            import shutil
            shutil.move(str(downloaded_path), str(target_path))
            # æ¸…ç†å¯èƒ½çš„ç©ºç›®å½•
            try:
                downloaded_path.parent.rmdir()
            except OSError:
                pass
        
        print(f"âœ… {model.name} ä¸‹è½½å®Œæˆ")
        return target_path
        
    except Exception as e:
        print(f"âŒ {model.name} ä¸‹è½½å¤±è´¥: {e}")
        raise


def download_all_models(
    cache_dir: Path,
    force_download: bool = False,
) -> Dict[str, Path]:
    """
    ä¸‹è½½æ‰€æœ‰æ¨¡å‹
    
    Args:
        cache_dir: ç¼“å­˜ç›®å½•
        force_download: æ˜¯å¦å¼ºåˆ¶é‡æ–°ä¸‹è½½
        
    Returns:
        æ¨¡å‹åç§°åˆ°æ–‡ä»¶è·¯å¾„çš„æ˜ å°„
    """
    print("=" * 60)
    print("ğŸ“¦ å¼€å§‹ä¸‹è½½ Qwen-Image-Edit-2511 æ¨¡å‹...")
    print("=" * 60)
    
    results = {}
    failed = []
    
    for model in MODELS:
        try:
            path = download_model_with_hf_hub(model, cache_dir, force_download)
            results[model.name] = path
        except Exception as e:
            failed.append((model.name, str(e)))
    
    print("\n" + "=" * 60)
    if failed:
        print("âš ï¸ ä»¥ä¸‹æ¨¡å‹ä¸‹è½½å¤±è´¥:")
        for name, error in failed:
            print(f"   - {name}: {error}")
    else:
        print("âœ… æ‰€æœ‰æ¨¡å‹ä¸‹è½½æˆåŠŸ!")
    print("=" * 60)
    
    return results


def verify_models(cache_dir: Path) -> Dict[str, bool]:
    """
    éªŒè¯æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    
    Args:
        cache_dir: ç¼“å­˜ç›®å½•
        
    Returns:
        æ¨¡å‹åç§°åˆ°å­˜åœ¨çŠ¶æ€çš„æ˜ å°„
    """
    results = {}
    for model in MODELS:
        target_path = cache_dir / model.local_dir / model.name
        results[model.name] = target_path.exists()
    return results


def get_missing_models(cache_dir: Path) -> List[ModelInfo]:
    """
    è·å–ç¼ºå¤±çš„æ¨¡å‹åˆ—è¡¨
    
    Args:
        cache_dir: ç¼“å­˜ç›®å½•
        
    Returns:
        ç¼ºå¤±çš„æ¨¡å‹åˆ—è¡¨
    """
    missing = []
    for model in MODELS:
        target_path = cache_dir / model.local_dir / model.name
        if not target_path.exists():
            missing.append(model)
    return missing


# ============================================================================
# å‘½ä»¤è¡Œå…¥å£
# ============================================================================

if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="ä¸‹è½½ Qwen-Image-Edit-2511 æ¨¡å‹")
    parser.add_argument(
        "--cache-dir",
        type=str,
        default="/cache/models",
        help="æ¨¡å‹ç¼“å­˜ç›®å½• (é»˜è®¤: /cache/models)",
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°ä¸‹è½½æ‰€æœ‰æ¨¡å‹",
    )
    parser.add_argument(
        "--verify",
        action="store_true",
        help="ä»…éªŒè¯æ¨¡å‹æ˜¯å¦å­˜åœ¨",
    )
    
    args = parser.parse_args()
    cache_dir = Path(args.cache_dir)
    
    if args.verify:
        print("ğŸ” éªŒè¯æ¨¡å‹æ–‡ä»¶...")
        results = verify_models(cache_dir)
        for name, exists in results.items():
            status = "âœ…" if exists else "âŒ"
            print(f"   {status} {name}")
    else:
        download_all_models(cache_dir, force_download=args.force)
